{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Iter0, Test Accuracy0.8193\n",
      "Iter1, Test Accuracy0.8338\n",
      "Iter2, Test Accuracy0.8932\n",
      "Iter3, Test Accuracy0.9006\n",
      "Iter4, Test Accuracy0.9047\n",
      "Iter5, Test Accuracy0.9072\n",
      "Iter6, Test Accuracy0.9086\n",
      "Iter7, Test Accuracy0.9107\n",
      "Iter8, Test Accuracy0.9121\n",
      "Iter9, Test Accuracy0.9124\n",
      "Iter10, Test Accuracy0.9144\n",
      "Iter11, Test Accuracy0.914\n",
      "Iter12, Test Accuracy0.9164\n",
      "Iter13, Test Accuracy0.9174\n",
      "Iter14, Test Accuracy0.9162\n",
      "Iter15, Test Accuracy0.917\n",
      "Iter16, Test Accuracy0.9191\n",
      "Iter17, Test Accuracy0.9196\n",
      "Iter18, Test Accuracy0.9197\n",
      "Iter19, Test Accuracy0.9198\n",
      "Iter20, Test Accuracy0.9208\n",
      "Iter21, Test Accuracy0.9211\n",
      "Iter22, Test Accuracy0.9212\n",
      "Iter23, Test Accuracy0.921\n",
      "Iter24, Test Accuracy0.9209\n",
      "Iter25, Test Accuracy0.9216\n",
      "Iter26, Test Accuracy0.9216\n",
      "Iter27, Test Accuracy0.9218\n",
      "Iter28, Test Accuracy0.9221\n",
      "Iter29, Test Accuracy0.9227\n",
      "Iter30, Test Accuracy0.9225\n",
      "Iter31, Test Accuracy0.9229\n",
      "Iter32, Test Accuracy0.9228\n",
      "Iter33, Test Accuracy0.9234\n",
      "Iter34, Test Accuracy0.9226\n",
      "Iter35, Test Accuracy0.9238\n",
      "Iter36, Test Accuracy0.9237\n",
      "Iter37, Test Accuracy0.923\n",
      "Iter38, Test Accuracy0.9235\n",
      "Iter39, Test Accuracy0.9236\n",
      "Iter40, Test Accuracy0.9239\n",
      "Iter41, Test Accuracy0.9239\n",
      "Iter42, Test Accuracy0.9242\n",
      "Iter43, Test Accuracy0.9241\n",
      "Iter44, Test Accuracy0.9241\n",
      "Iter45, Test Accuracy0.9248\n",
      "Iter46, Test Accuracy0.9247\n",
      "Iter47, Test Accuracy0.9247\n",
      "Iter48, Test Accuracy0.9249\n",
      "Iter49, Test Accuracy0.9247\n",
      "Iter50, Test Accuracy0.9252\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)\n",
    "\n",
    "# 每个批次的大小\n",
    "batch_size = 100\n",
    "# 计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "#参数概要\n",
    "def variable_summaries(var):\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean',mean)  # 平均值\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev',stddev)   #标准差\n",
    "        tf.summary.scalar('max', tf.reduce_max(var)) #最大值\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))  #最小值\n",
    "        tf.summary.histogram('histogram', var)  # 直方图\n",
    "\n",
    "# 命名空间\n",
    "with tf.name_scope('input'):\n",
    "    # 定义两个placeholder\n",
    "    x = tf.placeholder(\"float\", [None, 784],name='x-input')\n",
    "    y = tf.placeholder(\"float\", [None, 10],name='y-input')\n",
    "\n",
    "with tf.name_scope('layer'):\n",
    "    # 建立一个简单的神经网络\n",
    "    with tf.name_scope('wights'):\n",
    "        W = tf.Variable(tf.zeros([784,10]),name='W')\n",
    "        variable_summaries(W)\n",
    "    with tf.name_scope('biases'):\n",
    "        b = tf.Variable(tf.zeros([10]),name='b')\n",
    "        variable_summaries(b)\n",
    "    with tf.name_scope('wx_plus_b'):\n",
    "        wx_plus_b = tf.matmul(x,W) + b\n",
    "    with tf.name_scope('softmax'):\n",
    "        prediction = tf.nn.softmax(wx_plus_b)\n",
    "\n",
    "# 代价函数\n",
    " # （1）使用平方的方法\n",
    "#loss = tf.reduce_mean(tf.square(y - prediction))     \n",
    " # （2）使用交叉熵的方法改进 #########################################################\n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=prediction)) \n",
    "    tf.summary.scalar('loss',loss)\n",
    "with tf.name_scope('train'):\n",
    "    # 使用梯度下降法\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.15).minimize(loss)\n",
    "\n",
    "# 初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.name_scope('accuracy'):\n",
    "    with tf.name_scope('correct_prediction'):\n",
    "        # 结果存放在一个布尔型列表中\n",
    "        correct_prediction = tf.equal(tf.argmax(prediction,1), tf.argmax(y,1))      # argmax 返回一维变量中最大值所在位置\n",
    "    with tf.name_scope('accuracy'):\n",
    "        # 求准确率\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        tf.summary.scalar('accuracy',accuracy)\n",
    "\n",
    "# 合并所有的summary\n",
    "merged = tf.summary.merge_all()\n",
    "        \n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    writer = tf.summary.FileWriter('logs/',sess.graph)\n",
    "    for epoch in range(51):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "           # sess.run(train_step,feed_dict = {x:batch_xs, y:batch_ys})\n",
    "            summary, _ = sess.run([merged,train_step],feed_dict={x:batch_xs,y:batch_ys})\n",
    "          \n",
    "        writer.add_summary(summary,epoch)\n",
    "        acc = sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels})\n",
    "        print(\"Iter\" + str(epoch) + \", Test Accuracy\" + str(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
